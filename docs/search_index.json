[["index.html", "Thijmen Weijgertze DataScience portofolio 1 Main page", " Thijmen Weijgertze DataScience portofolio Thijmen Weijgertze 2023-06-06 1 Main page 1.0.1 Introduction This github page is written by Thijmen Weijgertze using Rstudio. I am a 3rd year Life Science student at HU University of Applied Sciences Utrecht. In the past half year I’ve followed a DataScience minor provided by the HU. This Github page serves as my DataScience portofolio for showing off my DataScience skills. The course is created by amdhaan et al. ([2020] 2021) based on the “bookdown: Authoring Books and Technical Documents with R Markdown” book from Xie (n.d.). 1.0.2 Contact information phone: 0630477492 www: https://thijmenweijgertze.github.io email: thijmen.lifesciences@gmail.com github: https://github.com/ThijmenWeijgertze linkedin: https://www.linkedin.com/in/thijmen-weijgertze-968a5a265/ "],["c.-elegans-plate-experiment.html", "2 C. Elegans plate experiment", " 2 C. Elegans plate experiment 2.0.1 Setup 2.0.1.0.1 Setting a seed and loading packages # Seed chosen based on the current year set.seed(2023) # Loading packages library(tidyverse) library(RColorBrewer) library(twPackage) library(readxl) 2.0.1.0.2 Importing and inspecting the data According to The data was kindly supplied by J. Louter (INT/ILC) and was derived from an experiment in which adult C.elegans nematodes were exposed to varying concentrations of different compounds. # importing xlsx file CE_LIQ_FLOW_062_Tidydata &lt;- read_excel( here::here( &quot;data_cElegansExp&quot;, &quot;CE.LIQ.FLOW.062_Tidydata.xlsx&quot; ) ) # inspecting data in table format with the reactable package tw_table(CE_LIQ_FLOW_062_Tidydata, pagesize = 5) 2.0.2 Scatterplot 2.0.2.0.1 Pseudocode Deciding which columns will be included in the scatterplot Checking and possibly changing the datatypes of those columns Plotting the data in a scatterplot using ggplot Normalizing y-axis counts Setting the x-axis to a log10 scale Adding jitter to spread out points on top of eachother 2.0.2.0.2 Checking and correcting datatypes needed for the scatterplot # Checking the data types of the following columns: RawData, compName, expType and compConcentration CE_LIQ_FLOW_062_Tidydata %&gt;% select(RawData, compName, compConcentration, expType) %&gt;% str() ## tibble [360 × 4] (S3: tbl_df/tbl/data.frame) ## $ RawData : num [1:360] 44 37 45 47 41 35 41 36 40 38 ... ## $ compName : chr [1:360] &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; ... ## $ compConcentration: chr [1:360] &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; ... ## $ expType : chr [1:360] &quot;experiment&quot; &quot;experiment&quot; &quot;experiment&quot; &quot;experiment&quot; ... # Changing compConcentration to numeric; changing compName into a factor; changing expType into a factor CE_LIQ_FLOW_062_Tidydata$compConcentration &lt;- parse_number(CE_LIQ_FLOW_062_Tidydata$compConcentration) CE_LIQ_FLOW_062_Tidydata$compName &lt;- factor(CE_LIQ_FLOW_062_Tidydata$compName, levels = unique(CE_LIQ_FLOW_062_Tidydata$compName)) CE_LIQ_FLOW_062_Tidydata$expType &lt;- factor(CE_LIQ_FLOW_062_Tidydata$expType, levels = unique(CE_LIQ_FLOW_062_Tidydata$expType)) # Checking the new dataypes and factor levels CE_LIQ_FLOW_062_Tidydata %&gt;% select(RawData, compName, compConcentration, expType) %&gt;% str() ## tibble [360 × 4] (S3: tbl_df/tbl/data.frame) ## $ RawData : num [1:360] 44 37 45 47 41 35 41 36 40 38 ... ## $ compName : Factor w/ 5 levels &quot;2,6-diisopropylnaphthalene&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ compConcentration: num [1:360] 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 4.99 ... ## $ expType : Factor w/ 4 levels &quot;experiment&quot;,&quot;controlPositive&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... levels(CE_LIQ_FLOW_062_Tidydata$compName) ## [1] &quot;2,6-diisopropylnaphthalene&quot; &quot;decane&quot; ## [3] &quot;naphthalene&quot; &quot;Ethanol&quot; ## [5] &quot;S-medium&quot; levels(CE_LIQ_FLOW_062_Tidydata$expType) ## [1] &quot;experiment&quot; &quot;controlPositive&quot; &quot;controlNegative&quot; &quot;controlVehicleA&quot; 2.0.3 normalizing data CE_LIQ_FLOW_062_contNeg &lt;- CE_LIQ_FLOW_062_Tidydata %&gt;% filter(expType == &quot;controlNegative&quot;) contNeg_mean &lt;- mean(CE_LIQ_FLOW_062_contNeg$RawData) contNeg_mean ## [1] 85.9 CE_LIQ_FLOW_062_Tidydata &lt;- CE_LIQ_FLOW_062_Tidydata %&gt;% mutate(normalized = RawData/mean(contNeg_mean)) mean(CE_LIQ_FLOW_062_Tidydata$RawData) ## [1] NA CE_LIQ_FLOW_062_Tidydata %&gt;% select(compName, expType, compConcentration, RawData, normalized) %&gt;% tw_table(pagesize = 5) CE_LIQ_FLOW_062_contNeg &lt;- CE_LIQ_FLOW_062_Tidydata %&gt;% filter(expType == &quot;controlNegative&quot;) contNegNorm_mean &lt;- mean(CE_LIQ_FLOW_062_contNeg$normalized) contNegNorm_mean ## [1] 1 # https://www.statology.org/how-to-normalize-data-in-r/ 2.0.3.0.1 Plotting the CE_LIQ_FLOW_062_normalized in a scatterplot # Plotting the CE_LIQ_FLOW_062_normalized in a scatterplot ggplot( data = CE_LIQ_FLOW_062_Tidydata, aes(x = log10(compConcentration), y = normalized) )+ geom_point( aes(color = compName, shape = expType), size = 1.5, alpha = 0.8, position = position_jitter(width = 0.1) # jitter to spread out values on top of eachother )+ labs( title = &quot;Scatterplot CE_LIQ_FLOW_062_Tidydata&quot;, caption = &quot;Data normalized with the negative control mean&quot;, x = &quot;log10(compConcentration) in nM&quot;, y = &quot;RawData in counts&quot; )+ scale_color_brewer(palette = &quot;Dark2&quot;) # colorblind friendly color scale Figure 2.1: The positive control for this experiments is controlPositive The negative control for this experiment is controlNegative 2.0.4 Statistical tests 2.0.4.0.1 Pseudocode Difference between the compound concentrations Loading the data Filter the concentrations per compound Plot the data using bargraph with the stdev as error bar Check the normality with a Shapio-Wilk test of both groups separately Perform an ANOVA test If the ANOVA test is significant, perform post hoc tests Draw a conclusion Difference between the LC50 curves Loading the data Filter the concentrations per compound Plotting the LC50 curves per compound Calculating 95% confidence intervals Checking the overlap between the 95% confidence intervals Draw conclusion "],["data-management.html", "3 Data management", " 3 Data management I’ve a reorganized the folders of an older project using the principles of the Guerilla analytics framework. To illustrate the folder structure I’ve made a directory tree using the fs package. # Creating a directory tree fs::dir_tree(path = here::here(&quot;data_management&quot;)) ## D:/thijmenweijgertze.github.io/data_management ## ├── bclxl_onecut2_project ## │ ├── bclxl_onecut2_project.Rproj ## │ ├── data_bam ## │ │ └── README.txt ## │ ├── data_counts ## │ │ └── README.txt ## │ ├── data_fastq ## │ │ └── README.txt ## │ ├── data_fastqc ## │ │ └── README.txt ## │ ├── docs ## │ │ ├── EindopdrachtDAUR2_V8.pdf ## │ │ └── README.txt ## │ ├── img ## │ │ ├── OC2_700_1.png ## │ │ ├── OC2_703_2.png ## │ │ ├── README.txt ## │ │ ├── SRR7866699_1.png ## │ │ ├── SRR7866699_2.png ## │ │ ├── SRR7866700_2.png ## │ │ ├── SRR7866703_1.png ## │ │ ├── SRR7866704_1.png ## │ │ └── SRR7866704_2.png ## │ ├── README.txt ## │ └── rmd ## │ ├── eind_opdracht.html ## │ ├── eind_opdracht.Rmd ## │ ├── eind_opdracht_dian_thijmen.html ## │ ├── eind_opdracht_dian_thijmen.Rmd ## │ └── README.txt ## ├── hg38 ## │ ├── hg38_annotation ## │ │ └── README.txt ## │ ├── hg38_genome ## │ │ └── README.txt ## │ ├── hg38_index ## │ │ └── README.txt ## │ └── README.txt ## ├── metagenomics_formatief ## │ ├── data_bracken ## │ │ ├── mock2.bracken ## │ │ └── README.txt ## │ ├── data_fastq ## │ │ └── README.txt ## │ ├── data_fastqc ## │ │ ├── HU2_MOCK2_L001_R1_001_fastqc.html ## │ │ ├── HU2_MOCK2_L001_R1_001_fastqc.zip ## │ │ ├── HU2_MOCK2_L001_R2_001_fastqc.html ## │ │ ├── HU2_MOCK2_L001_R2_001_fastqc.zip ## │ │ └── README.txt ## │ ├── data_kraken2 ## │ │ ├── mock2.report ## │ │ ├── mock2_bracken_species.biom ## │ │ ├── mock2_bracken_species.report ## │ │ └── README.txt ## │ ├── img ## │ │ ├── fastqc_mock2_R1_per_base_quality.png ## │ │ ├── fastqc_mock2_R2_per_base_quality.png ## │ │ ├── kracken_principle.png ## │ │ └── README.txt ## │ ├── metagenomics_formatief.Rproj ## │ ├── README.txt ## │ ├── rmd ## │ │ ├── Formatieve_opdracht.docx ## │ │ ├── Formatieve_opdracht.html ## │ │ ├── Formatieve_opdracht.Rmd ## │ │ └── README.txt ## │ └── yml ## │ ├── README.txt ## │ └── setup_meta_env.yml ## ├── metagenomics_species_identification ## │ ├── data_bracken ## │ │ ├── mock1.bracken ## │ │ └── README.txt ## │ ├── data_fastq ## │ │ └── README.txt ## │ ├── data_fastqc ## │ │ ├── HU1_MOCK1_L001_R1_001_fastqc.html ## │ │ ├── HU1_MOCK1_L001_R1_001_fastqc.zip ## │ │ ├── HU1_MOCK1_L001_R2_001_fastqc.html ## │ │ ├── HU1_MOCK1_L001_R2_001_fastqc.zip ## │ │ └── README.txt ## │ ├── data_kraken2 ## │ │ ├── mock1.report ## │ │ ├── mock1_bracken_species.biom ## │ │ ├── mock1_bracken_species.report ## │ │ └── README.txt ## │ ├── img ## │ │ ├── fastqc_mock1_R1_per_base_quality.png ## │ │ ├── fastqc_mock1_R2_per_base_quality.png ## │ │ └── README.txt ## │ ├── metagenomics_species_identification.Rproj ## │ ├── README.txt ## │ ├── rmd ## │ │ ├── aantekeningen.txt ## │ │ ├── metagenomics_reader.html ## │ │ ├── metagenomics_reader.Rmd ## │ │ ├── original_metagenomics_reader.html ## │ │ ├── original_metagenomics_reader.Rmd ## │ │ └── README.txt ## │ └── yml ## │ ├── README.txt ## │ └── setup_meta_env.yml ## ├── README.txt ## ├── rnaseq_fibroblast_iPSC ## │ ├── data_bam ## │ │ └── README.txt ## │ ├── data_counts ## │ │ └── README.txt ## │ ├── data_fastq ## │ │ └── README.txt ## │ ├── data_fastqc ## │ │ └── README.txt ## │ ├── data_sampledata ## │ │ ├── data_sampledata.csv ## │ │ ├── raw ## │ │ │ └── data_sampledata.csv ## │ │ └── README.txt ## │ ├── docs ## │ │ ├── Notes.txt ## │ │ ├── opdracht_info.html ## │ │ └── README.txt ## │ ├── README.txt ## │ ├── rmd ## │ │ ├── Formatieve_opdracht.Rmd ## │ │ ├── README.txt ## │ │ └── v01 ## │ │ └── Formatieve_opdracht.Rmd ## │ └── rnaseq_fibroblast_iPSC.Rproj ## └── rnaseq_reader ## ├── data_bam ## │ └── README.txt ## ├── data_counts ## │ └── README.txt ## ├── data_fastq ## │ └── README.txt ## ├── data_fastqc ## │ └── README.txt ## ├── docs ## │ ├── notes.txt ## │ ├── opdracht_info.html ## │ └── README.txt ## ├── README.txt ## ├── rmd ## │ ├── README.txt ## │ └── rnaseq_reader.Rmd ## └── rnaseq_reader.Rproj "],["thijmen-weijgertze-datascience-cv.html", "4 Thijmen Weijgertze DataScience CV", " 4 Thijmen Weijgertze DataScience CV 4.0.1 Who am I Hi I’m “Thijmen Weijgertze” a 20 year old student from Ede, Gelderland (2003). I tend to be very passionate about my study and love to talk about topics surrounding Life Sciences. As of writing this résumé I live with my parents, sister and our dog “Saartje” (breed: markiesje). In my free time my biggest hobby is music. I produce music from time to time and play piano almost daily. Besides music I also like to spent time with friends in the weekends and cycle so now and then. 4.0.2 My education 4.0.3 My most relevant skills related to DataScience (alphabetical order) [Assembly tools] I’ve worked with the assembly tools Unicycler, PlasmidEC and Gplas. These tools I’ve used within a project where we (our project group) assembled plasmids from bacterial illumina NGS data. This project was commissioned by the RIVM. [Bash] I’m capable of writing in Bash [Cell biology] I’ve theoretical knowledge about the principles of the cell such as cell metabolism and cellular communication [Cell culture] I’m capable of working and running experiments with cell cultures [Git/Github] I’ve worked with git/github workflows [Immunology] I’ve theoretical knowledge about the principles regarding immunology [Metagenomics] I’m capable of writing a pipeline for downstream metagenomics data [NGS] I’ve theoretical knowledge about the NGS principles of Pac-bio, Illumina and Nanopore [Oncology] I’ve theoretical knowledge about the hallmarks of tumorcells [PCR] I’m experienced with PCR both practicly and theoreticly [Reproducibility] I’m experienced regarding reproducible research [R] I’m capable of writing in R and experienced with rmarkdown. See my DataScience portofolio [RNA/DNA isolation] I’m capable of isolating RNA/DNA (including creating a cDNA bank) [RNA-seq] I’m capable of writing a pipeline for downstream rna-seq analysis using DESeq2 (with results such as heatmaps, count plots, volcano plots, up/downregulated genes [Statistics] I’m capable of parametric and non-parametric tests and writing a conclusion based on the results 4.0.4 Contact info phone: 0630477492 www: https://thijmenweijgertze.github.io email: thijmen.lifesciences@gmail.com github: https://github.com/ThijmenWeijgertze linkedin: https://www.linkedin.com/in/thijmen-weijgertze-968a5a265/ "],["relational-databases.html", "5 Relational databases", " 5 Relational databases 5.0.1 Setup # loading packages library(tidyverse) library(dslabs) library(here) library(reactable) library(twPackage) The flu and dengue data sets are retrieved from Google Inc. [Google Inc. (2015b) ; Google Inc. (2015a)]. The gapminder data set is retrieved from the dslabs package [Irizarry and Gill (2023)]. 5.0.2 Reading in files # loading flu data flu_data &lt;- read.csv( here::here( &quot;data_relationalDatabases&quot;, &quot;flu_data.csv&quot; ), skip = 11 # skip the first 11 lines ) # loading dengue data dengue_data &lt;- read.csv( here::here( &quot;data_relationalDatabases&quot;, &quot;dengue_data.csv&quot; ), skip = 11 # skip the first 11 lines ) # loading gapminder data gap_data &lt;- gapminder 5.0.3 Inspecting data # inspecting flu data tw_table(flu_data, pagesize = 5) # inspecting dengue data tw_table(dengue_data, pagesize = 5) # inspecting gapminder data tw_table(gap_data, pagesize = 5) The flu dataset must be changed into tidy format. The flu and dengue data tidy the countries will be stored under one column named “country”. The date column will be separated into the columns: year, month and day. 5.0.4 Making the data tidy ## making flu data tidy # creating the country column flu_tidy &lt;- pivot_longer( data = flu_data, cols = c(Argentina:Uruguay), values_to = &quot;search_activity&quot;, names_to = &quot;country&quot; ) # creating year month and date columns flu_tidy &lt;- separate( flu_tidy, Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), convert = TRUE, sep = &quot;-&quot; ) ## making dengue data tidy # creating the country column dengue_tidy &lt;- pivot_longer( data = dengue_data, cols = c(Argentina:Venezuela), values_to = &quot;search_activity&quot;, names_to = &quot;country&quot; ) # creating year month and date columns dengue_tidy &lt;- separate( dengue_tidy, Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), convert = TRUE, sep = &quot;-&quot; ) # the gapminder data is already tidy gap_tidy &lt;- gap_data 5.0.5 Inspecting the tidy data # inspecting flu tidy tw_table(flu_tidy, pagesize = 5) # inspecting dengue tidy tw_table(flu_tidy, pagesize = 5) # inspecting gapminder tidy tw_table(flu_tidy, pagesize = 5) 5.0.6 Exporting the tidy data as .csv and .rds format # exporting flu tidy to .csv and .rds format tw_csv_rds(flu_tidy, &quot;data_relationalDatabases/flu_tidy&quot;) # exporting dengue tidy to .csv and .rds format tw_csv_rds(dengue_tidy, &quot;data_relationalDatabases/dengue_tidy&quot;) # exporting gap tidy to .csv and .rds format tw_csv_rds(gap_tidy, &quot;data_relationalDatabases/gap_tidy&quot;) 5.0.7 Making connection to the DBeaver database # loading packages to connect R with the database library(DBI) # connecting to database con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=readRDS(here::here(&quot;db_pass.rds&quot;))) # put here your own password 5.0.8 Loading files into the database # Connect with the database and export the data to DBeaver dbWriteTable(con, &quot;flu_tidy&quot;, flu_tidy) dbWriteTable(con, &quot;dengue_tidy&quot;, dengue_tidy) dbWriteTable(con, &quot;gap_tidy&quot;, gap_tidy) 5.0.9 Inspecting data with SQL In the following code blocks there will be examples of using SQL to inspect the database data. -- In specting dengue data with SQL select country from dengue_tidy; Table 5.1: Displaying records 1 - 10 country Argentina Bolivia Brazil India Indonesia Mexico Philippines Singapore Thailand Venezuela -- flu data from the Netherlands without NA values ordered by search_activity select * from flu_tidy where search_activity is not null and country=&#39;Netherlands&#39; order by search_activity desc; Table 5.2: Displaying records 1 - 10 year month day country search_activity 2013 1 27 Netherlands 270 2013 1 20 Netherlands 233 2009 11 8 Netherlands 199 2015 2 8 Netherlands 193 2009 1 18 Netherlands 184 2003 12 21 Netherlands 177 2013 2 3 Netherlands 174 2013 2 10 Netherlands 172 2009 11 1 Netherlands 168 2003 12 14 Netherlands 159 -- amount of rows in dengue data without NA SELECT COUNT(*) FROM dengue_tidy where search_activity is not null; Table 5.3: 1 records count 6263 5.0.10 joining the tables into a new table The tables will be joined into a new table. This new table will be used later on to plot the flu_search against the data per country within the South American region. -- joining the tables using SQL create table joined_tidy as SELECT -- columns to be included in the table flu_tidy.year, flu_tidy.month, flu_tidy.day, gap_tidy.continent, gap_tidy.region, flu_tidy.country, flu_tidy.search_activity as flu_search, dengue_tidy.search_activity as dengue_search FROM flu_tidy LEFT JOIN dengue_tidy ON -- joining the dengue dataset with the flu dataset based on date and country dengue_tidy.year = flu_tidy.year AND dengue_tidy.month = flu_tidy.month AND dengue_tidy.day = flu_tidy.day AND dengue_tidy.country = flu_tidy.country LEFT JOIN gap_tidy ON -- joining the gapminder dataset with the flu dataset based on year and country gap_tidy.year = flu_tidy.year AND gap_tidy.country = flu_tidy.country; [Rahul (2014); “SQL | Join (Inner, Left, Right and Full Joins)” (2016)] 5.0.11 Inspecting the joined tidy dataset -- inspecting the new table and saving to select * from joined_tidy The data is saved as a variable called joined_tidy by adding ‘output.var=“joined_tidy”’ to the chunk header (langtang 2022). # inspecting joined tidy variable tw_table(joined_tidy, pagesize = 5) # exporting joined tidy to .csv and .rds format tw_csv_rds(joined_tidy, path = &quot;data_relationalDatabases/joined_tidy&quot;) # disconnecting from the database # since the joined_tidy dataset is now stored in a R variable dbDisconnect(con) 5.0.12 plotting the flu_search against the data per country within the South American region # plotting flu search against the date per South American country joined_tidy %&gt;% mutate(date = mdy(paste(month,day,year, sep = &quot;-&quot;))) %&gt;% filter(region == &quot;South America&quot;) %&gt;% select(flu_search, date, country, region) %&gt;% na.omit() %&gt;% ggplot(aes(x = date, y = flu_search, fill = country)) + geom_col(aes(colour = country)) + scale_x_date(date_breaks = &quot;1 year&quot;, date_labels = &quot;%Y&quot;) + theme(axis.text.x=element_text(angle=60, hjust=1), legend.position = &quot;none&quot;) + facet_wrap(~country, scales=&#39;free&#39;) "],["twpackage.html", "6 twPackage", " 6 twPackage 6.0.1 Introduction The package consists of 4 functions for a DataScience portofolio. The package is created with the following guide: Handley Wickham and Jennifer Bryan (2023). 6.0.2 Installation The package can be installed via github: - devtools::install_github(“ThijmenWeijgertze/twPackage”, build_vignettes = TRUE) The twPackage makes use of the following packages - here - reactable - readr - dplyr - magrittr Suggested packages: - knitr - rmarkdown 6.0.3 Function and data explanation tw_factor() description: This command changes a column type to factor with unique levels using the unique() command usage: tw_factor(x) x: The column to be changed into a factor returns: Column with type factor tw_csv_rds() description: This command exports a variable containing a dataframe or tibble into a .csv and .rds file at a chosen location. The packages relies on the readr and here package. A project must be loaded in order to make this command work usage: tw_csv_rds(x, path) x Dataframe or tibble path The path where the files must be stored. The path must be specified starting at the rproject directory. Do not add .csv or .rds at the end of the file name returns: A .csv and .tsv from a dataframe or tibble at the chosen location tw_table() description: This command creates a basic table with the reactable package. usage: tw_table(x) x: A variable containing a dataframe or tibble returns: A basic table made with the reactable package tw_filter_select() description: This command creates a basic table with the reactable package. usage: tw_filter_select(x, filter_col, filter_value, select) x: The table to be filtered filter_col: The column where the filter_value can be found filter_value: The value to be filtered on select: The columns to be selected returns: A filtered and selected data Pokemon data description: A dataframe with 800 rows and 13 columns containing pokemon data from around 2016. usage: pokemon returns: The pokemon dataset source: Pokemon data 6.0.4 Function examples loading package # load package library(twPackage) tw_factor() # Changing column Type.1 into a factor with unique levels pokemon$Type.1 &lt;- tw_factor(pokemon$Type.1) levels(pokemon$Type.1) ## [1] &quot;Grass&quot; &quot;Fire&quot; &quot;Water&quot; &quot;Bug&quot; &quot;Normal&quot; &quot;Poison&quot; ## [7] &quot;Electric&quot; &quot;Ground&quot; &quot;Fairy&quot; &quot;Fighting&quot; &quot;Psychic&quot; &quot;Rock&quot; ## [13] &quot;Ghost&quot; &quot;Ice&quot; &quot;Dragon&quot; &quot;Dark&quot; &quot;Steel&quot; &quot;Flying&quot; tw_csv_rds() # Exporting the pokemon table as pokemon.csv and pokemon.rds in the pokemon_data folder tw_csv_rds(pokemon, path = &quot;data_pokemon/pokemon&quot;) tw_table() # creating a table with 5 rows per page tw_table(pokemon, pagesize = 5) tw_filter_select() # Filtering on Type.1 = Fire and selecting the columns Name and Type.1 tw_filter_select( pokemon, filter_col = &quot;Type.1&quot;, filter_value = &quot;Fire&quot;, select = c(&quot;Name&quot;, &quot;Type.1&quot;) ) %&gt;% head(5) ## Name Type.1 ## 1 Charmander Fire ## 2 Charmeleon Fire ## 3 Charizard Fire ## 4 CharizardMega Charizard X Fire ## 5 CharizardMega Charizard Y Fire "],["machine-learning.html", "7 Machine learning", " 7 Machine learning "],["setup-2.html", "8 Setup 8.1 The Tidymodels get-started-guide", " 8 Setup # loading libraries library(here) library(tidyverse) library(reactable) 8.0.1 Plan of action 8.0.1.0.1 Introduction During the “Data Science for biology 2” course every student has the opportunity to learn a new skill for their portfolio. I (Thijmen Weijgertze) have decided to learn the myself the basics of “Machine Learning”. This skill will be learned in a span of ca. 4 weeks (around 30 hours). To learn this skill I have set up a goal with a corresponding planning to achieve the this goal. 8.0.1.0.2 Goal At the end of this course I want to have created an algorithm able to predict the recurrence of breast cancer using the breast-cancer.data dataset. This algorithm will be written in R using principles from “tidymodels”, “CART”, “random forest” and possibly other Machine Learning techniques I’ll come across. 8.0.1.0.3 Planning Week 1 (7th - 14th of September): Delving into the principles of “tidymodels”, “CART”, “random forest” Week 2 (14th - 21th of September): Writing my first Machine Learning algorithm Week 3-4 (21th - 6th of June): Apply the learned skills on the breast-cancer.data dataset to predict the recurrence of breast cancer 8.0.1.0.4 Dataset # loading in data bcData &lt;- read.csv( here::here( &quot;data_machineLearning&quot;, &quot;breast-cancer.data&quot; ), header = FALSE, # dataset does not contain column names col.names = c(&quot;class&quot;, &quot;age&quot;, &quot;menopause&quot;, &quot;tumor_size&quot;, &quot;inv_nodes&quot;, &quot;node_caps&quot;, &quot;deg_malig&quot;, &quot;breast&quot;, &quot;breast_quad&quot;, &quot;irradiat&quot;) # setting column names ) # presenting data in table form reactable( bcData, filterable = TRUE, compact = TRUE, bordered = TRUE, defaultPageSize = 5 ) This breast cancer domain was obtained from the University Medical Centre, Institute of Oncology, Ljubljana, Yugoslavia. Thanks go to M. Zwitter and M. Soklic for providing the data. The breast-cancer.data domain consist of a total of 286 rows and 10 columns. From which 201 instances are no-recurrence-events and 85 instances are recurrence-events. 8.1 The Tidymodels get-started-guide In order to build a model the tidymodels package and some additional packages must be installed. # install.packages(&quot;tidymodels&quot;) # main package # # # helper packages in order to use the data included in the tidymodels guide # install.packages(&quot;readr&quot;) # install.packages(&quot;broom.mixed&quot;) # install.packages(&quot;dotwhisker&quot;) # loading in the installed packages library(tidymodels) library(readr) library(broom.mixed) library(dotwhisker) For this guide sea urchin data can be loaded from https://tidymodels.org/start/models/urchins.csv # loading in the data urchins &lt;- read.csv(&quot;https://tidymodels.org/start/models/urchins.csv&quot;) # inspecting the data and data types reactable( urchins, filterable = TRUE, compact = TRUE, bordered = TRUE, defaultPageSize = 5 ) "],["bibliography.html", "9 bibliography", " 9 bibliography "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
